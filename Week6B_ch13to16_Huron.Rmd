---
title: "Week6B_Ch13t16_Huron"
author: "Nicholas Huron"
date: "2/27/2018"
output: html_document
---

```{r setup}
#packages required
library(tidyverse)
library(nycflights13)
library(stringr)
library(forcats)
library(lubridate)
#some global params
knitr::opts_chunk$set(echo = T)
#set the dir
knitr::opts_knit$set(root.dir="/Volumes/GoogleDrive/My Drive/QuantSci_GP/")
```

##Chapter 13
###Exercises 13.2.1

 3. Weather only contains information for the origin (NYC) airports. If it contained weather records for all airports in the USA, what additional relation would it define with flights?
  
It would also relate to day, month, year, dest (destination), and hour in flights. With additional data, you might also expect additional destination time data in the weather dataset too.

###Exercises 13.3.1
  2. Identify the keys in the following datasets (You might need to install some packages and read some documentation.):
    
    - `Lahman::Batting`
```{r}
Lahman::Batting %>%
  group_by(playerID, yearID, stint) %>%
  summarise(id = n()) %>%
  filter(id > 1)
```

>a combined primary key is the only one apparent in the dataset (contains the vars mentioned above).

    - `babynames::babynames`
```{r}
babynames::babynames %>%
  group_by(year, sex, name) %>%
  summarise(id = n()) %>%
  filter(id > 1)
```    

>As with the previous dataset, a combined primary key exists that combines a year identify with two others. This one includes sex and baby name!

    - `nasaweather::atmos`
```{r}
nasaweather::atmos %>%
  group_by(lat, long, year, month) %>%
  summarise(id = n()) %>%
  filter(id > 1)
```

>Here, the primary key consists of location coordinates and date identifiers (year and month).

    - `fueleconomy::vehicles`
```{r}
fueleconomy::vehicles %>%
  group_by(id) %>%
  summarise(ID = n()) %>%
  filter(ID > 1)
```
>Here, there is a single variable that is the primary key, `id`.

    - `ggplot2::diamonds`
```{r}
ggplot2::diamonds %>%
  group_by(price, carat, cut, color, clarity, x, y, z, depth, table) %>%
  summarise(ID = n()) %>%
  filter(ID > 1)
```
>This dataset does not have a primary key. Even when grouping by all variables, there are still multiples.

###Exercises 13.4.6
  2. Add the location of the origin and destination (i.e. the lat and lon) to flights.

```{r}
flights %>%
  left_join(airports, by = c("origin" = "faa")) %>%
  left_join(airports, by = c("dest" = "faa"))
```

>Origins are all .x cols and destinations are all .y cols!

###Exercises 13.5.1
  2. Filter flights to only show flights with planes that have flown at least 100 flights.
```{r}
hundred <- flights %>%
  group_by(tailnum) %>%
  summarise(n_flights = n()) %>%
  filter(n_flights > 99)

semi_join(flights, hundred, by = "tailnum") %>%
  group_by(tailnum) %>%
  summarise(n_flights = n()) %>%
  arrange(n_flights)
```

##Chapter 14
###Exercises 14.2.5
  1. In code that doesn’t use stringr, you’ll often see paste() and paste0(). What’s the difference between the two functions? What stringr function are they equivalent to? How do the functions differ in their handling of NA?
  
These two functions differ in their requirement of the `sep =` parameter. `paste()` requires this parameter to dictate how strings should be connected, whereas `paste0()` assumes that there are no characters between strings. For `stringr`, the `str_c()` function works like `paste()` and has a `sep=` parameter, that when set to `sep=""` will behave like `paste0()`.
  
  2. In your own words, describe the difference between the sep and collapse arguments to str_c().
  
`sep` will include the provided string in between the output strings if they come from different sources (e.g., using `LETTERS` and `letters` in a `str_c()`). Collapse will combine all of the output elements into a single element, with the provided string as a separator between otherwise distinct elements in the vector. Normally, the input and `sep` values are combined but indexing is preserved, so you end up with a vector of length equal to the longest input string. In other words, `collapse` further combines them.

###Exercises 14.4.2
  2. What word has the highest number of vowels? What word has the highest proportion of vowels? (Hint: what is the denominator?)

```{r most vowels}
df <- tibble(
  word = words, 
  i = seq_along(word)
)

df %>%
  mutate(n_vowels = str_count(word, "[aeiou]")) %>%
  arrange(desc(n_vowels))
```

There is a **8-way** tie for the most vowels, with several words containing *5* vowels each!

```{r biggest prop vowels}
df <- tibble(
  word = words, 
  i = seq_along(word)
)

df %>%
  mutate(n_vowels = str_count(word, "[aeiou]")) %>%
  arrange(desc(n_vowels)) %>%
  mutate(n_cons = str_count(word, "[^aeiou]")) %>%
  mutate(prop_vowels = n_vowels / (n_cons + n_vowels)) %>%
  arrange(desc(prop_vowels))
```

As for the proportion, the answer is simply the letter **a**, as it contains one vowel and no other characters (proprtion = 1.0). This can be calculated with more complex regex's to get the total number of characters for the denominator or with just the sum of vowels + not vowels per word.

###Exercises 14.4.6.1
  2. Why is it better to split up by boundary("word") than " "?
  
`boundary("word")` accounts for other types of whitespace and punctuation, which would not be picked up by a regex with `" "`. Thus, you get cleaner cuts when trying to split words up!

##Chapter 15
###Exercises 15.3.1
  2. What is the most common relig in this survey? What’s the most common partyid?
  
```{r find relig and partyid}
#find most common relig
gss_cat %>%
  count(relig) %>%
  arrange(desc(n))

#find most common partyid
gss_cat %>%
  count(partyid) %>%
  arrange(desc(n))
```

The most common `relig` is Protestant, and the most common `partyid` is Indepedent.

###Exercises 15.4.1
  2. For each factor in gss_cat identify whether the order of the levels is arbitrary or principled.
  
```{r find factors in gss_cat}
(fctrs <- gss_cat %>%
  select_if(., is.factor) %>%
  colnames(.))
```

So *stack overflow* queries suggest using the `select_if` function! We can see that the above printed strings are the names of the columns that are factors. We can now evaluate them to see which contain levels that are principled versus arbitrary.
```{r determine leveling}
for(a in 1:length(fctrs)){
  print(fctrs[a])
  print(levels(gss_cat[[as.character(fctrs[a])]]))
  gss_cat %>%
    group_by(gss_cat[[as.character(fctrs[a])]]) %>%
    summarise(n()) %>%
    print(.)
  print("----------------------------------------")
}
```

This loop gives us the names of each factor column, the levels, and prints a summary table. Each summary table takes on the ordering of the levels. Let's unpack it:
  1. `marital`: ordered somewhat (no answer is a type of `NA` almost that makes it tough to order levels). It appears to go from levels of single-ness/distance from being married to married-ness, but I would consider swapping `"divorced"` and `"separated"` to make this order more of the continuum one would expect for emotional/psychological state relative to married.
  
  2. `race`: ordered by number of observations in increasing order.
  
  3. `rincome`: ordered in decreasing value, though odd-ball answers (`no answer, Don't know, Refused,` and `Not applicable`) are not grouped together.
  
  4. `partyid`: ordered along political spectrum from conservative (republican) to liberal (democrat), with the same caveat as `rincome`, but all odd-ball answers are grouped at the front together. 
  
  5. `relig`: appears ordered arbitrarily.
  
  6. `denom`: appears ordered arbitrarily.

###Exercises 15.5.1
  1. How have the proportions of people identifying as Democrat, Republican, and Independent changed over time?
  
```{r props}
gss_cat %>%
  mutate(partyid2 = fct_collapse(partyid,
    democrat = c("Not str democrat", "Strong democrat"),
    republican = c("Strong republican", "Not str republican"),
    independent = c("Ind,near rep", "Ind,near dem", "Independent"),
    other = c("No answer", "Don't know", "Other party")
  )) %>%
  count(partyid2, year) %>%
  group_by(year) %>%
  mutate(proportion = n / sum(n)) %>%
  ggplot() +
  geom_line(mapping = aes(x = year, y = proportion, color = partyid2))

```

For `other`, there is little change. `republican` drops the most of all, whereas `democrat` may appear to drop somewhat. Unlike the rest, `independent` grows.

##Chapter 16
###Exercises 16.2.4
  3. Use the appropriate lubridate function to parse each of the following dates:
  
```{r parse dates}
  d1 <- "January 1, 2010"
mdy(d1)
  d2 <- "2015-Mar-07"
ymd(d2)
  d3 <- "06-Jun-2017"
dmy(d3)
  d4 <- c("August 19 (2015)", "July 1 (2015)")
mdy(d4)
  d5 <- "12/30/14" # Dec 30, 2014
mdy(d5)
```
  
###Exercises 16.3.4
  6. What makes the distribution of diamonds$carat and flights$sched_dep_time similar?
  
```{r}
#diamonds$carat
ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = carat))
#flights$sched_dep_time
#code from book to make flights easier to look at

make_datetime_100 <- function(year, month, day, time) {
  make_datetime(year, month, day, time %/% 100, time %% 100)
}

flights_dt <- flights %>% 
  filter(!is.na(dep_time), !is.na(arr_time)) %>% 
  mutate(
    dep_time = make_datetime_100(year, month, day, dep_time),
    arr_time = make_datetime_100(year, month, day, arr_time),
    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),
    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)
  ) %>% 
  select(origin, dest, ends_with("delay"), ends_with("time"))

flights_dt %>%
  ggplot() +
  geom_bar(mapping = aes(x = minute(sched_dep_time)))

```

We can look at the plots to be sure, but I believe both suffer from the human bias that Hadley mentions, such that humans like "nice" numbers. With `diamonds$carat` the nice numbers are increments of whole carats or half carats, and with `flights$sched_dep_time`, it is the same with flights departing on the hour, half hour, etc.